# Call Summary Project

## Overview
This project allows users to upload audio files (live or prerecorded) and processes the audio to:
- Generate transcriptions with speaker diarization (identifying different speakers).
- Summarize each speakerâ€™s conversation and provide an overall conversation summary.
- Generate audio statistics including duration, total word count, and words spoken by each speaker.

Built using **FastAPI**, this project integrates tools like **Whisper** for transcription and the **Groq API** for summarization.

## Features
1. **Audio Upload**: Users can upload an audio file (e.g., `.wav` format).
2. **Transcription**: The system generates a transcription, identifying individual speakers using diarization.
3. **Speaker Summaries**: The conversations of each speaker are summarized separately.
4. **Conversation Summary**: A summary of the entire conversation is generated.
5. **Statistics**: The system provides detailed stats including:
    - Audio duration (in minutes).
    - Total word count.
    - Word count breakdown per speaker.

## Technologies Used
- **FastAPI**: Web framework for building APIs.
- **Whisper**: Speech-to-text transcription.
- **Groq API**: Used for generating conversation summaries.
- **Python**: Backend processing, data handling, and summarization.
- **Docker** (Optional): For containerized deployment.

## Project Architecture
![Project_Architecture](https://github.com/user-attachments/assets/2b3a17e4-546b-42df-907b-0ca8bf6857fe)

## Project Demo

[![Watch this video](https://github.com/user-attachments/assets/310a0738-dfdb-47b9-bbe7-392a78a5c5bb)](https://github.com/user-attachments/assets/ed91f1d0-7b7c-4050-aca2-a1740e953502)

## **How to Set Up the FastAPI Project Locally**
## Setup Instructions
### 1. Clone the Repository
First, clone the project repository to your local machine:
```bash
git clone https://github.com/SaiKumarSeela/Call-Summary.git
cd Call-Summary
```

### 2. Create and Activate a Virtual Environment
It is recommended to use a virtual environment to manage dependencies:
```bash
# Create a virtual environment (use python3 if necessary)
python -m venv venv

# Activate the virtual environment
# On Windows
venv\Scripts\activate
# On macOS/Linux
source venv/bin/activate
```

### 3. Install Dependencies
Install the required Python dependencies using `pip`:
```bash
pip install -r requirements.txt
```

### 4. Set Up Environment Variables
Create a `.env` file in the root of your project directory to store environment variables. Include the following:

```bash
HUGGINGFACEHUB_API_TOKEN=your-huggingface-api-token
GROQ_API_KEY=your-groq-api-key
```

Make sure to replace `your-huggingface-api-token` and `your-groq-api-key` with the actual tokens from the respective services.

### 5. Install and Set Up Whisper Model
This project uses **Whisper** for transcription. Ensure you have the necessary dependencies installed:
```bash
pip install git+https://github.com/openai/whisper.git
```

### 6. Running the Project Locally
Once everything is set up, you can run the project using the following command:
```bash
uvicorn main:app --reload
```

The server will start on `http://127.0.0.1:8000`.

### 7. Test the API
Once the project is running, you can access the API documentation automatically generated by **FastAPI** at:
```
http://127.0.0.1:8000/docs
```

Use the interactive interface to upload audio files and test the endpoints:
- `/transcribe/` for uploading and transcribing audio.
- `/summary/` to get conversation summaries.
- `/stats/` to fetch audio statistics.


### 8. Docker Setup
To run this project inside a Docker container, follow these steps:

#### Step 1: Build Docker Image
If you have Docker installed, build the Docker image:
```bash
docker build -t <img_name> .
```

#### Step 2: Run the Docker Container
Run the Docker container after building the image:
```bash
docker run -d -p 8000:8000 -e GROQ_API_KEY="you_api_key" -e HUGGINGFACEHUB_API_TOKEN="your_huggingface_token" <img_name>
```

Now you can access the project on `http://127.0.0.1:8000`.

